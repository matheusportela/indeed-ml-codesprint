{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Machine Learning CodeSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the important packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_train_data(filename):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    with open(filename) as fd:\n",
    "        reader = csv.reader(fd, delimiter='\\t')\n",
    "\n",
    "        # ignore header row\n",
    "        next(reader, None)\n",
    "        \n",
    "        for row in reader:\n",
    "            X.append(row[1])\n",
    "            y.append(row[0].split())\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = load_train_data('../data/train.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some input and output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: THE COMPANY    Employer is a midstream service provider to the onshore Oil and Gas markets.  It is a a fast growing filtration technology company providing environmentally sound solutions to the E&P’s for water and drilling fluids management and recycling.    THE POSITION    The North Dakota Regional Technical Sales Representative reports directly to the VP of Sales and covers a territory that includes North Dakota and surrounding areas of South Dakota, Wyoming and Montana.  Specific duties for this position include but are not limited to:     Building sales volume within the established territory from existing and new accounts   Set up and maintain a strategic sales plan for the territory   Present technical presentations, product demonstrations & training   Maintain direct contact with customers, distributors and representatives   Prospect new customer contacts and referrals   Gather and record customer & competitor information   Provide accurate and updated forecasts for the territory   Identify new product opportunities   Build long-term relationships with customers, reps & distributors    CANDIDATE REQUIREMENT    The ideal candidate will possess technical degree, preferably in the oil & gas discipline and/or 5+ years of experience preferably with exploration and production companies (midstream service companies are a big plus).      Other desired requirements include but are not limited to:     Consistent record of superior sales results & experience closing sales   Proven ability to cold-call, develop relationships   Excellent written and verbal communication skills.    Strong computer skills, including Word, Excel, PowerPoint, e-mail, etc.   Strong work ethic and ability to work independently.   Must be willing to develop new business – not just maintain current accounts   Ability to travel extensively throughout assigned region    If you are a self-motivated individual with strong engineering, and leadership skills and a desire to build a stronger, more advanced organization we encourage you to apply.      Position is located in North Dakota, but sales representative could live as far away as Casper, Wyoming or Billings, Montana.     Successful candidates must pass a post offer background and drug screen.    EOE         \n",
      "\n",
      "Output: ['licence-needed', 'supervising-job', '5-plus-years-experience-needed']\n"
     ]
    }
   ],
   "source": [
    "print 'Input:', X[0]\n",
    "print\n",
    "print 'Output:', y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input data preprocessor as bag-of-words and tf-idf feature extraction:\n",
    "\n",
    "- `CountVectorizer`: Transforms text to vector of occurrences for each word found in training set (bag-of-words representation).\n",
    "- `TfidfTransformer`: Transforms bag-of-words to its relative frequency, removing too frequent or rare words from the final representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "X_preprocessor = Pipeline([\n",
    "    ('count', CountVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define multi-label binarizer for output data. Each target sample will be a binary array: 0 if not present, 1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_preprocessors = {\n",
    "    'job': LabelEncoder(),\n",
    "    'wage': LabelEncoder(),\n",
    "    'degree': LabelEncoder(),\n",
    "    'experience': LabelEncoder(),\n",
    "    'supervising': LabelEncoder()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classifier as SVM with one-vs-all strategy for multilabel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# F1 score: 0.422\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {\n",
    "    'job': OneVsRestClassifier(LinearSVC()),\n",
    "    'wage': OneVsRestClassifier(LinearSVC()),\n",
    "    'degree': OneVsRestClassifier(LinearSVC()),\n",
    "    'experience': OneVsRestClassifier(LinearSVC()),\n",
    "    'supervising': OneVsRestClassifier(LinearSVC())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate targets for mutually exclusive tags\n",
    "def split_exclusive_tags(y):\n",
    "    split_y = {\n",
    "        'job': [],\n",
    "        'wage': [],\n",
    "        'degree': [],\n",
    "        'experience': [],\n",
    "        'supervising': []\n",
    "    }\n",
    "    \n",
    "    for target in y:\n",
    "        split_y['job'].append(filter(lambda x: x in ['part-time-job', 'full-time-job'], target))\n",
    "        split_y['wage'].append(filter(lambda x: x in ['hourly-wage', 'salary'], target))\n",
    "        split_y['degree'].append(filter(lambda x: x in ['associate-needed', 'bs-degree-needed', 'ms-or-phd-needed', 'licence-needed'], target))\n",
    "        split_y['experience'].append(filter(lambda x: x in ['1-year-experience-needed', '2-4-years-experience-needed', '5-plus-years-experience-needed'], target))\n",
    "        split_y['supervising'].append(filter(lambda x: x in ['supervising-job'], target))\n",
    "        \n",
    "    return split_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of label occurrences for each tag type\n",
    "def calculate_tag_type_count(split_y, tag_type):\n",
    "    count = {}\n",
    "    \n",
    "    for y_type in split_y[tag_type]:\n",
    "        y_type = y_type[0] if y_type else ''\n",
    "        \n",
    "        if y_type not in count:\n",
    "            count[y_type] = 0\n",
    "\n",
    "        count[y_type] += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate stratified indicies considering the minimum number of label occurrences for each tag type\n",
    "# For instance, given the data y = [0, 1, 1, 2, 3, 3, 3, 3, 2, 2, 1, 0], the minimum number of label occurrences is 2\n",
    "# for label \"0\". Hence, the output will be something like [1, 2, 3, 4, 5, 6, 9, 11], where each class will have only\n",
    "# two occurrences.\n",
    "def stratify_classes(X, split_y, tag_type):\n",
    "    tag_type_count = calculate_tag_type_count(split_y, tag_type)\n",
    "    min_tag_type_count = min([count for _, count in tag_type_count.items()])\n",
    "    \n",
    "    stratified_indices = []\n",
    "    stratification_count = {}\n",
    "    \n",
    "    for i, y in enumerate(split_y[tag_type]):\n",
    "        index = y[0] if y else ''\n",
    "        \n",
    "        if index not in stratification_count:\n",
    "            stratification_count[index] = 0\n",
    "        else:\n",
    "            stratification_count[index] += 1\n",
    "        \n",
    "        if stratification_count[index] < min_tag_type_count:\n",
    "            stratified_indices.append(i)\n",
    "    \n",
    "    stratified_X = X[stratified_indices]\n",
    "    stratified_y = np.array([y for i, y in enumerate(split_y[tag_type]) if i in stratified_indices])\n",
    "    \n",
    "    return stratified_X, stratified_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_models(models, X_preprocessor, y_preprocessors, X, y):\n",
    "    print 'Fitting models'\n",
    "    split_y = split_exclusive_tags(y)\n",
    "\n",
    "    X_processed = X_preprocessor.fit_transform(X)\n",
    "    \n",
    "    for tag_type, model in models.items():\n",
    "        stratified_X, stratified_y = stratify_classes(X, split_y, tag_type)\n",
    "        \n",
    "        # Learn one preprocessor for each mutually exclusive tag\n",
    "        X_processed = X_preprocessor.transform(stratified_X)\n",
    "        y_processed = y_preprocessors[tag_type].fit_transform(stratified_y)\n",
    "        \n",
    "        # Learn one model for each mutually exclusive tag\n",
    "        model.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_models(models, X_preprocessor, y_preprocessors, X):\n",
    "    print 'Predicting with models'\n",
    "    \n",
    "    output = [[] for _ in X]\n",
    "    \n",
    "    for tag_type, model in models.items():\n",
    "        # Preprocess and use model for the given type of tag\n",
    "        X_processed = X_preprocessor.transform(X)\n",
    "        model_output = model.predict(X_processed)\n",
    "        \n",
    "        tag_type_output = y_preprocessors[tag_type].inverse_transform(model_output)\n",
    "\n",
    "        # Aggregate outputs for all types of tags in the same array\n",
    "        for i, out in enumerate(tag_type_output):\n",
    "            if type(out) in [list, tuple]:\n",
    "                output[i].extend(out)\n",
    "            else:\n",
    "                output[i].append(out)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_test, y_output):\n",
    "    print 'Calculating F1 score'\n",
    "    \n",
    "    tags = ['part-time-job', 'full-time-job', 'hourly-wage', 'salary', 'associate-needed', 'bs-degree-needed',\n",
    "            'ms-or-phd-needed', 'licence-needed', '1-year-experience-needed', '2-4-years-experience-needed',\n",
    "            '5-plus-years-experience-needed', 'supervising-job']\n",
    "\n",
    "    true_positive = np.array([0.0 for _ in tags])\n",
    "    true_negative = np.array([0.0 for _ in tags])\n",
    "    false_positive = np.array([0.0 for _ in tags])\n",
    "    false_negative = np.array([0.0 for _ in tags])\n",
    "    \n",
    "    for target, output in zip(y_test, y_output):\n",
    "        for i, tag in enumerate(tags):\n",
    "            if tag in target and tag in output:\n",
    "                true_positive[i] += 1\n",
    "            elif tag not in target and tag not in output:\n",
    "                true_negative[i] += 1\n",
    "            elif tag in target and tag not in output:\n",
    "                false_negative[i] += 1\n",
    "            elif tag not in target and tag in output:\n",
    "                false_positive[i] += 1\n",
    "            else:\n",
    "                raise Exception('Unknown situation - tag: {} target: {} output: {}'.format(tag, target, output))\n",
    "                \n",
    "    tags_precision = np.array([0.0 for _ in tags])\n",
    "    tags_recall = np.array([0.0 for _ in tags])\n",
    "    tags_f1_score = np.array([0.0 for _ in tags])\n",
    "    \n",
    "    for i, tag in enumerate(tags):\n",
    "        tags_precision[i] = true_positive[i] / (true_positive[i] + false_positive[i])\n",
    "        tags_recall[i] = true_positive[i] / (true_positive[i] + false_negative[i])\n",
    "        tags_f1_score[i] = 2*tags_precision[i]*tags_recall[i] / (tags_precision[i] + tags_recall[i])\n",
    "        \n",
    "    min_tags_precision = np.argmin(tags_precision)\n",
    "    min_tags_recall = np.argmin(tags_recall)\n",
    "    min_tags_f1_score = np.argmin(tags_f1_score)\n",
    "    \n",
    "    print\n",
    "    print '{:30s} | {:5s} | {:5s} | {:5s}'.format('Tag', 'Prec.', 'Rec. ', 'F1')\n",
    "    for i in range(len(tags)):\n",
    "        print '{:30s} | {:.3f} | {:.3f} | {:.3f}'.format(\n",
    "            tags[i], tags_precision[i], tags_recall[i], tags_f1_score[i])\n",
    "    print\n",
    "    \n",
    "    print 'Worst precision:', tags[min_tags_precision]\n",
    "    print 'Worst recall:', tags[min_tags_recall]\n",
    "    print 'Worst F1 score:', tags[min_tags_f1_score]\n",
    "    print\n",
    "        \n",
    "    precision = np.sum(true_positive) / (np.sum(true_positive) + np.sum(false_positive))\n",
    "    recall = np.sum(true_positive) / (np.sum(true_positive) + np.sum(false_negative))\n",
    "    f1_score = 2*precision*recall / (precision + recall)\n",
    "    \n",
    "    print 'General:'\n",
    "    print 'Precision: {:.3f}'.format(precision)\n",
    "    print 'Recall: {:.3f}'.format(recall)\n",
    "    print 'F1 score: {:.3f}'.format(f1_score)\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1 score with cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.283 | 0.739 | 0.410\n",
      "full-time-job                  | 0.315 | 0.599 | 0.413\n",
      "hourly-wage                    | 0.418 | 0.772 | 0.542\n",
      "salary                         | 0.382 | 0.779 | 0.512\n",
      "associate-needed               | 0.148 | 0.500 | 0.228\n",
      "bs-degree-needed               | 0.624 | 0.584 | 0.603\n",
      "ms-or-phd-needed               | 0.215 | 0.636 | 0.322\n",
      "licence-needed                 | 0.362 | 0.600 | 0.452\n",
      "1-year-experience-needed       | 0.155 | 0.517 | 0.239\n",
      "2-4-years-experience-needed    | 0.443 | 0.297 | 0.356\n",
      "5-plus-years-experience-needed | 0.376 | 0.623 | 0.469\n",
      "supervising-job                | 0.469 | 0.757 | 0.579\n",
      "\n",
      "Worst precision: associate-needed\n",
      "Worst recall: 2-4-years-experience-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.367\n",
      "Recall: 0.592\n",
      "F1 score: 0.453\n",
      "#0 F1 score: 0.453\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.269 | 0.852 | 0.409\n",
      "full-time-job                  | 0.402 | 0.580 | 0.474\n",
      "hourly-wage                    | 0.272 | 0.747 | 0.399\n",
      "salary                         | 0.333 | 0.635 | 0.437\n",
      "associate-needed               | 0.100 | 0.529 | 0.168\n",
      "bs-degree-needed               | 0.527 | 0.535 | 0.531\n",
      "ms-or-phd-needed               | 0.116 | 0.556 | 0.192\n",
      "licence-needed                 | 0.357 | 0.451 | 0.398\n",
      "1-year-experience-needed       | 0.172 | 0.455 | 0.250\n",
      "2-4-years-experience-needed    | 0.448 | 0.278 | 0.343\n",
      "5-plus-years-experience-needed | 0.423 | 0.641 | 0.510\n",
      "supervising-job                | 0.410 | 0.705 | 0.519\n",
      "\n",
      "Worst precision: associate-needed\n",
      "Worst recall: 2-4-years-experience-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.334\n",
      "Recall: 0.555\n",
      "F1 score: 0.417\n",
      "#1 F1 score: 0.417\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.274 | 0.863 | 0.416\n",
      "full-time-job                  | 0.373 | 0.515 | 0.432\n",
      "hourly-wage                    | 0.342 | 0.837 | 0.485\n",
      "salary                         | 0.379 | 0.633 | 0.474\n",
      "associate-needed               | 0.123 | 0.476 | 0.196\n",
      "bs-degree-needed               | 0.461 | 0.515 | 0.486\n",
      "ms-or-phd-needed               | 0.115 | 0.667 | 0.196\n",
      "licence-needed                 | 0.282 | 0.402 | 0.332\n",
      "1-year-experience-needed       | 0.160 | 0.516 | 0.244\n",
      "2-4-years-experience-needed    | 0.424 | 0.309 | 0.358\n",
      "5-plus-years-experience-needed | 0.404 | 0.619 | 0.489\n",
      "supervising-job                | 0.414 | 0.777 | 0.540\n",
      "\n",
      "Worst precision: ms-or-phd-needed\n",
      "Worst recall: 2-4-years-experience-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.329\n",
      "Recall: 0.567\n",
      "F1 score: 0.417\n",
      "#2 F1 score: 0.417\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.281 | 0.756 | 0.410\n",
      "full-time-job                  | 0.342 | 0.527 | 0.415\n",
      "hourly-wage                    | 0.368 | 0.848 | 0.513\n",
      "salary                         | 0.335 | 0.675 | 0.448\n",
      "associate-needed               | 0.172 | 0.556 | 0.263\n",
      "bs-degree-needed               | 0.495 | 0.614 | 0.548\n",
      "ms-or-phd-needed               | 0.118 | 0.571 | 0.195\n",
      "licence-needed                 | 0.366 | 0.553 | 0.440\n",
      "1-year-experience-needed       | 0.205 | 0.530 | 0.295\n",
      "2-4-years-experience-needed    | 0.451 | 0.311 | 0.368\n",
      "5-plus-years-experience-needed | 0.423 | 0.658 | 0.515\n",
      "supervising-job                | 0.444 | 0.752 | 0.558\n",
      "\n",
      "Worst precision: ms-or-phd-needed\n",
      "Worst recall: 2-4-years-experience-needed\n",
      "Worst F1 score: ms-or-phd-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.348\n",
      "Recall: 0.597\n",
      "F1 score: 0.440\n",
      "#3 F1 score: 0.440\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.235 | 0.729 | 0.355\n",
      "full-time-job                  | 0.384 | 0.476 | 0.425\n",
      "hourly-wage                    | 0.324 | 0.819 | 0.464\n",
      "salary                         | 0.382 | 0.633 | 0.476\n",
      "associate-needed               | 0.143 | 0.500 | 0.222\n",
      "bs-degree-needed               | 0.404 | 0.497 | 0.446\n",
      "ms-or-phd-needed               | 0.182 | 0.857 | 0.300\n",
      "licence-needed                 | 0.321 | 0.542 | 0.403\n",
      "1-year-experience-needed       | 0.164 | 0.597 | 0.257\n",
      "2-4-years-experience-needed    | 0.402 | 0.275 | 0.327\n",
      "5-plus-years-experience-needed | 0.415 | 0.562 | 0.478\n",
      "supervising-job                | 0.407 | 0.716 | 0.519\n",
      "\n",
      "Worst precision: associate-needed\n",
      "Worst recall: 2-4-years-experience-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.322\n",
      "Recall: 0.556\n",
      "F1 score: 0.408\n",
      "#4 F1 score: 0.408\n",
      "\n",
      "Total F1 score: 0.427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "for i, (train, validation) in enumerate(k_fold.split(X)):\n",
    "    X_train, X_validation, y_train, y_validation = X[train], X[validation], y[train], y[validation]\n",
    "\n",
    "    fit_models(models, X_preprocessor, y_preprocessors, X_train, y_train)\n",
    "    y_output = predict_models(models, X_preprocessor, y_preprocessors, X_validation)\n",
    "    \n",
    "    score = calculate_f1_score(y_validation, y_output)\n",
    "    scores.append(score)\n",
    "    print '#{0} F1 score: {1:.3f}'.format(i, score)\n",
    "    print\n",
    "    \n",
    "f1_score = np.mean(scores)\n",
    "    \n",
    "print 'Total F1 score: {0:.3f}'.format(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_test_data(filename):\n",
    "    with open(filename) as fd:\n",
    "        reader = csv.reader(fd, delimiter='\\t')\n",
    "        next(reader, None) # ignore header row\n",
    "        X = [row[0] for row in reader]\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "X_train, y_train = load_train_data('../data/train.tsv')\n",
    "X_test = load_test_data('../data/test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with all training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models\n"
     ]
    }
   ],
   "source": [
    "fit_models(models, X_preprocessor, y_preprocessors, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict output from test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with models\n"
     ]
    }
   ],
   "source": [
    "y_output = predict_models(models, X_preprocessor, y_preprocessors, X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hourly-wage', 'part-time-job', 'supervising-job', '1-year-experience-needed'], ['supervising-job', '5-plus-years-experience-needed', 'bs-degree-needed'], ['hourly-wage', 'part-time-job', 'bs-degree-needed'], ['hourly-wage', 'part-time-job'], ['2-4-years-experience-needed', 'bs-degree-needed'], ['hourly-wage', 'part-time-job'], ['hourly-wage', 'part-time-job', '1-year-experience-needed'], ['hourly-wage', '5-plus-years-experience-needed'], ['hourly-wage'], []]\n"
     ]
    }
   ],
   "source": [
    "print y_output[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_output(filename, output):\n",
    "    with open(filename, 'w') as fd:\n",
    "        fd.write('tags\\n')\n",
    "        \n",
    "        for i, tags in enumerate(output):\n",
    "            fd.write(' '.join(tags))\n",
    "            \n",
    "            if i < len(output) - 1:\n",
    "                fd.write('\\n')\n",
    "            \n",
    "save_output('../data/tags.tsv', y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save preprocessors and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(filename, obj):\n",
    "    pickle.dump(obj, open(filename, 'w'))\n",
    "\n",
    "save('../models/X_preprocessor.pickle', X_preprocessor)\n",
    "save('../models/y_preprocessor.pickle', y_preprocessors)\n",
    "save('../models/clf_{0:.3f}_f1_score.pickle'.format(f1_score), models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    return pickle.load(open(filename))\n",
    "\n",
    "models = load('../models/clf_0.461_f1_score.pickle')\n",
    "X_preprocessors = load('../models/X_preprocessor.pickle')\n",
    "y_preprocessors = load('../models/y_preprocessor.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
