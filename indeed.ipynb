{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Machine Learning CodeSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the important packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_train_data(filename):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    with open(filename) as fd:\n",
    "        reader = csv.reader(fd, delimiter='\\t')\n",
    "\n",
    "        # ignore header row\n",
    "        next(reader, None)\n",
    "        \n",
    "        for row in reader:\n",
    "            X.append(row[1])\n",
    "            y.append(row[0].split())\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = load_train_data('data/train.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some input and output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: THE COMPANY    Employer is a midstream service provider to the onshore Oil and Gas markets.  It is a a fast growing filtration technology company providing environmentally sound solutions to the E&P’s for water and drilling fluids management and recycling.    THE POSITION    The North Dakota Regional Technical Sales Representative reports directly to the VP of Sales and covers a territory that includes North Dakota and surrounding areas of South Dakota, Wyoming and Montana.  Specific duties for this position include but are not limited to:     Building sales volume within the established territory from existing and new accounts   Set up and maintain a strategic sales plan for the territory   Present technical presentations, product demonstrations & training   Maintain direct contact with customers, distributors and representatives   Prospect new customer contacts and referrals   Gather and record customer & competitor information   Provide accurate and updated forecasts for the territory   Identify new product opportunities   Build long-term relationships with customers, reps & distributors    CANDIDATE REQUIREMENT    The ideal candidate will possess technical degree, preferably in the oil & gas discipline and/or 5+ years of experience preferably with exploration and production companies (midstream service companies are a big plus).      Other desired requirements include but are not limited to:     Consistent record of superior sales results & experience closing sales   Proven ability to cold-call, develop relationships   Excellent written and verbal communication skills.    Strong computer skills, including Word, Excel, PowerPoint, e-mail, etc.   Strong work ethic and ability to work independently.   Must be willing to develop new business – not just maintain current accounts   Ability to travel extensively throughout assigned region    If you are a self-motivated individual with strong engineering, and leadership skills and a desire to build a stronger, more advanced organization we encourage you to apply.      Position is located in North Dakota, but sales representative could live as far away as Casper, Wyoming or Billings, Montana.     Successful candidates must pass a post offer background and drug screen.    EOE         \n",
      "\n",
      "Output: ['licence-needed', 'supervising-job', '5-plus-years-experience-needed']\n"
     ]
    }
   ],
   "source": [
    "print 'Input:', X[0]\n",
    "print\n",
    "print 'Output:', y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing definition\n",
    "\n",
    "Preprocessing steps are applied differently for input vectors and target vectors.\n",
    "\n",
    "### Input preprocessing\n",
    "\n",
    "First, we need to transform the input text into a numerical representation. This is done by generating a vector where each position is the number of occurrences for a given word in the data.\n",
    "\n",
    "For instance, given the text `hello. this is my first line. this is my next line. this is the final one`, its [**count vector**](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), considering that the first position is with respect to `this`, the second is `line` and the third is `final` is `[3, 2, 1]`. The count vector did not use any stop words but only considered words that appeared at least 2 times in the training data, with maximum frequency of `95%`.\n",
    "\n",
    "Next, we apply [**tf-idf**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to weight the words according to their importance. Too frequent or too rare words are less important than the others.\n",
    "\n",
    "### Output preprocessing\n",
    "\n",
    "Usually, the output is given as a list of tags for each description, such as `[['part-time-job', 'salary', 'supervising-job'], ['2-4-years-experience-required', 'hourly-wage']]`. However, since some tags are mutually exclusive (only one can exist at a time), we take that into account. For instance, no description can be both `'part-time-job'` and `'full-time-job'` at the same time.\n",
    "\n",
    "Therefore, the target vector is splitted into several vectors, one for each mutually exclusive set of tags, in a format such as:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'job': [['part-time-job'], ['full-time-job'], ['part-time-job']],\n",
    "    'wage': [['salary'], [], []],\n",
    "    'degree': [[], [], []],\n",
    "    'experience': [[], [], []],\n",
    "    'supervising': [[], [], ['supervising-job']]\n",
    "}\n",
    "```\n",
    "\n",
    "With the splitted target vector, we will be able to train one model for each tag type.\n",
    "\n",
    "After that, each tag type target label will be [**encoded**](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) in numerical format, where each tag will be replaced by an integer. For instance, `[['part-time-job'], ['full-time-job'], [], ['part-time-job'], []]` may be encoded to `[1, 2, 0, 1, 0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input data preprocessor as bag-of-words and tf-idf feature extraction:\n",
    "\n",
    "- `CountVectorizer`: Transforms text to vector of occurrences for each word found in training set (bag-of-words representation).\n",
    "- `TfidfTransformer`: Transforms bag-of-words to its relative frequency, removing too frequent or rare words from the final representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "X_preprocessor = Pipeline([\n",
    "    ('count', CountVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2))),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define multi-label binarizer for output data. Each target sample will be a binary array: 0 if not present, 1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_preprocessors = {\n",
    "    'job': LabelEncoder(),\n",
    "    'wage': LabelEncoder(),\n",
    "    'degree': LabelEncoder(),\n",
    "    'experience': LabelEncoder(),\n",
    "    'supervising': LabelEncoder()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target vector `y` into one vector for each mutually exclusive tag type:\n",
    "\n",
    "```python\n",
    ">>> y = [['part-time-job', 'salary'], ['full-time-job'], ['part-time-job', 'supervising-job']]\n",
    ">>> split_y = split_exclusive_tags(y)\n",
    ">>> split_y\n",
    "{\n",
    "    'job': [['part-time-job'], ['full-time-job'], ['part-time-job']],\n",
    "    'wage': [['salary'], [], []],\n",
    "    'degree': [[], [], []],\n",
    "    'experience': [[], [], []],\n",
    "    'supervising': [[], [], ['supervising-job']]\n",
    "}\n",
    "```\n",
    "\n",
    "This is a useful step when training one model for each exclusive tag type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate targets for mutually exclusive tags\n",
    "def split_exclusive_tags(y):\n",
    "    split_y = {\n",
    "        'job': [],\n",
    "        'wage': [],\n",
    "        'degree': [],\n",
    "        'experience': [],\n",
    "        'supervising': []\n",
    "    }\n",
    "    \n",
    "    for target in y:\n",
    "        split_y['job'].append(filter(lambda x: x in ['part-time-job', 'full-time-job'], target))\n",
    "        split_y['wage'].append(filter(lambda x: x in ['hourly-wage', 'salary'], target))\n",
    "        split_y['degree'].append(filter(lambda x: x in ['associate-needed', 'bs-degree-needed', 'ms-or-phd-needed', 'licence-needed'], target))\n",
    "        split_y['experience'].append(filter(lambda x: x in ['1-year-experience-needed', '2-4-years-experience-needed', '5-plus-years-experience-needed'], target))\n",
    "        split_y['supervising'].append(filter(lambda x: x in ['supervising-job'], target))\n",
    "        \n",
    "    return split_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classifier as SVM with one-vs-all strategy for multilabel classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# F1 score: 0.511\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {\n",
    "    'job': OneVsRestClassifier(LinearSVC()),\n",
    "    'wage': OneVsRestClassifier(LinearSVC()),\n",
    "    'degree': OneVsRestClassifier(LinearSVC()),\n",
    "    'experience': OneVsRestClassifier(LinearSVC()),\n",
    "    'supervising': OneVsRestClassifier(LinearSVC())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each mutually exclusive tag type, we train one multiclass model capable of deciding which tag (or even none) is appropriate for the given input.\n",
    "\n",
    "Initially, an attempt of a single multilabel model was used, which would be able to output multiple labels at once. However, considering that the input space was huge for this situation, better results were achieved by using multiclass models, one for each mutually exclusive tag type. Thus the output would be the output for each tag type model aggregated in a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_models(models, X_preprocessor, y_preprocessors, X, y):\n",
    "    print 'Fitting models'\n",
    "    split_y = split_exclusive_tags(y)\n",
    "\n",
    "    X_processed = X_preprocessor.fit_transform(X)\n",
    "    \n",
    "    for tag_type, model in models.items():\n",
    "        # Learn one preprocessor for each mutually exclusive tag\n",
    "        X_processed = X_preprocessor.transform(X)\n",
    "        y_processed = y_preprocessors[tag_type].fit_transform(split_y[tag_type])\n",
    "        \n",
    "        # Learn one model for each mutually exclusive tag\n",
    "        model.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the output by executing the model for each tag type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_models(models, X_preprocessor, y_preprocessors, X):\n",
    "    print 'Predicting with models'\n",
    "    \n",
    "    output = [[] for _ in X]\n",
    "    \n",
    "    for tag_type, model in models.items():\n",
    "        # Preprocess and use model for the given type of tag\n",
    "        X_processed = X_preprocessor.transform(X)\n",
    "        model_output = model.predict(X_processed)\n",
    "        \n",
    "        tag_type_output = y_preprocessors[tag_type].inverse_transform(model_output)\n",
    "\n",
    "        # Aggregate outputs for all types of tags in the same array\n",
    "        for i, out in enumerate(tag_type_output):\n",
    "            if type(out) in [list, tuple]:\n",
    "                output[i].extend(out)\n",
    "            else:\n",
    "                output[i].append(out)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the F1 score given the target vector and the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_f1_score(y_test, y_output):\n",
    "    print 'Calculating F1 score'\n",
    "    \n",
    "    tags = ['part-time-job', 'full-time-job', 'hourly-wage', 'salary', 'associate-needed', 'bs-degree-needed',\n",
    "            'ms-or-phd-needed', 'licence-needed', '1-year-experience-needed', '2-4-years-experience-needed',\n",
    "            '5-plus-years-experience-needed', 'supervising-job']\n",
    "\n",
    "    true_positive = np.array([0.0 for _ in tags])\n",
    "    true_negative = np.array([0.0 for _ in tags])\n",
    "    false_positive = np.array([0.0 for _ in tags])\n",
    "    false_negative = np.array([0.0 for _ in tags])\n",
    "    \n",
    "    for target, output in zip(y_test, y_output):\n",
    "        for i, tag in enumerate(tags):\n",
    "            if tag in target and tag in output:\n",
    "                true_positive[i] += 1\n",
    "            elif tag not in target and tag not in output:\n",
    "                true_negative[i] += 1\n",
    "            elif tag in target and tag not in output:\n",
    "                false_negative[i] += 1\n",
    "            elif tag not in target and tag in output:\n",
    "                false_positive[i] += 1\n",
    "            else:\n",
    "                raise Exception('Unknown situation - tag: {} target: {} output: {}'.format(tag, target, output))\n",
    "                \n",
    "    tags_precision = np.array([0.0 for _ in tags])\n",
    "    tags_recall = np.array([0.0 for _ in tags])\n",
    "    tags_f1_score = np.array([0.0 for _ in tags])\n",
    "    \n",
    "    for i, tag in enumerate(tags):\n",
    "        tags_precision[i] = true_positive[i] / (true_positive[i] + false_positive[i])\n",
    "        tags_recall[i] = true_positive[i] / (true_positive[i] + false_negative[i])\n",
    "        tags_f1_score[i] = 2*tags_precision[i]*tags_recall[i] / (tags_precision[i] + tags_recall[i])\n",
    "        \n",
    "    min_tags_precision = np.argmin(tags_precision)\n",
    "    min_tags_recall = np.argmin(tags_recall)\n",
    "    min_tags_f1_score = np.argmin(tags_f1_score)\n",
    "    \n",
    "    print\n",
    "    print '{:30s} | {:5s} | {:5s} | {:5s}'.format('Tag', 'Prec.', 'Rec. ', 'F1')\n",
    "    for i in range(len(tags)):\n",
    "        print '{:30s} | {:.3f} | {:.3f} | {:.3f}'.format(\n",
    "            tags[i], tags_precision[i], tags_recall[i], tags_f1_score[i])\n",
    "    print\n",
    "    \n",
    "    print 'Worst precision:', tags[min_tags_precision]\n",
    "    print 'Worst recall:', tags[min_tags_recall]\n",
    "    print 'Worst F1 score:', tags[min_tags_f1_score]\n",
    "    print\n",
    "        \n",
    "    precision = np.sum(true_positive) / (np.sum(true_positive) + np.sum(false_positive))\n",
    "    recall = np.sum(true_positive) / (np.sum(true_positive) + np.sum(false_negative))\n",
    "    f1_score = 2*precision*recall / (precision + recall)\n",
    "    \n",
    "    print 'General:'\n",
    "    print 'Precision: {:.3f}'.format(precision)\n",
    "    print 'Recall: {:.3f}'.format(recall)\n",
    "    print 'F1 score: {:.3f}'.format(f1_score)\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with 5-fold cross-validation using the F1 score metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.727 | 0.348 | 0.471\n",
      "full-time-job                  | 0.740 | 0.341 | 0.467\n",
      "hourly-wage                    | 0.882 | 0.380 | 0.531\n",
      "salary                         | 0.630 | 0.234 | 0.342\n",
      "associate-needed               | 1.000 | 0.020 | 0.039\n",
      "bs-degree-needed               | 0.757 | 0.808 | 0.781\n",
      "ms-or-phd-needed               | 1.000 | 0.045 | 0.087\n",
      "licence-needed                 | 0.662 | 0.410 | 0.506\n",
      "1-year-experience-needed       | 0.769 | 0.172 | 0.282\n",
      "2-4-years-experience-needed    | 0.571 | 0.482 | 0.523\n",
      "5-plus-years-experience-needed | 0.514 | 0.514 | 0.514\n",
      "supervising-job                | 0.790 | 0.379 | 0.512\n",
      "\n",
      "Worst precision: 5-plus-years-experience-needed\n",
      "Worst recall: associate-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.673\n",
      "Recall: 0.439\n",
      "F1 score: 0.532\n",
      "#0 F1 score: 0.532\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.941 | 0.262 | 0.410\n",
      "full-time-job                  | 0.618 | 0.312 | 0.415\n",
      "hourly-wage                    | 0.829 | 0.387 | 0.527\n",
      "salary                         | 0.757 | 0.222 | 0.344\n",
      "associate-needed               | 0.667 | 0.059 | 0.108\n",
      "bs-degree-needed               | 0.737 | 0.785 | 0.760\n",
      "ms-or-phd-needed               | 0.500 | 0.056 | 0.100\n",
      "licence-needed                 | 0.647 | 0.292 | 0.402\n",
      "1-year-experience-needed       | 0.222 | 0.030 | 0.053\n",
      "2-4-years-experience-needed    | 0.543 | 0.468 | 0.502\n",
      "5-plus-years-experience-needed | 0.555 | 0.465 | 0.506\n",
      "supervising-job                | 0.757 | 0.340 | 0.469\n",
      "\n",
      "Worst precision: 1-year-experience-needed\n",
      "Worst recall: 1-year-experience-needed\n",
      "Worst F1 score: 1-year-experience-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.653\n",
      "Recall: 0.393\n",
      "F1 score: 0.491\n",
      "#1 F1 score: 0.491\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.839 | 0.356 | 0.500\n",
      "full-time-job                  | 0.671 | 0.333 | 0.445\n",
      "hourly-wage                    | 0.854 | 0.357 | 0.504\n",
      "salary                         | 0.857 | 0.234 | 0.368\n",
      "associate-needed               | nan | 0.000 | nan\n",
      "bs-degree-needed               | 0.729 | 0.819 | 0.771\n",
      "ms-or-phd-needed               | 1.000 | 0.067 | 0.125\n",
      "licence-needed                 | 0.610 | 0.414 | 0.493\n",
      "1-year-experience-needed       | 0.857 | 0.097 | 0.174\n",
      "2-4-years-experience-needed    | 0.567 | 0.531 | 0.549\n",
      "5-plus-years-experience-needed | 0.592 | 0.484 | 0.533\n",
      "supervising-job                | 0.747 | 0.468 | 0.575\n",
      "\n",
      "Worst precision: associate-needed\n",
      "Worst recall: associate-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.681\n",
      "Recall: 0.439\n",
      "F1 score: 0.534\n",
      "#2 F1 score: 0.534\n",
      "\n",
      "Fitting models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:31: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.857 | 0.308 | 0.453\n",
      "full-time-job                  | 0.676 | 0.375 | 0.483\n",
      "hourly-wage                    | 0.820 | 0.390 | 0.529\n",
      "salary                         | 0.667 | 0.200 | 0.308\n",
      "associate-needed               | 1.000 | 0.022 | 0.043\n",
      "bs-degree-needed               | 0.720 | 0.795 | 0.756\n",
      "ms-or-phd-needed               | nan | 0.000 | nan\n",
      "licence-needed                 | 0.701 | 0.382 | 0.495\n",
      "1-year-experience-needed       | 0.875 | 0.084 | 0.154\n",
      "2-4-years-experience-needed    | 0.507 | 0.528 | 0.518\n",
      "5-plus-years-experience-needed | 0.570 | 0.453 | 0.505\n",
      "supervising-job                | 0.727 | 0.366 | 0.487\n",
      "\n",
      "Worst precision: ms-or-phd-needed\n",
      "Worst recall: ms-or-phd-needed\n",
      "Worst F1 score: ms-or-phd-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.657\n",
      "Recall: 0.404\n",
      "F1 score: 0.500\n",
      "#3 F1 score: 0.500\n",
      "\n",
      "Fitting models\n",
      "Predicting with models\n",
      "Calculating F1 score\n",
      "\n",
      "Tag                            | Prec. | Rec.  | F1   \n",
      "part-time-job                  | 0.839 | 0.371 | 0.515\n",
      "full-time-job                  | 0.719 | 0.369 | 0.488\n",
      "hourly-wage                    | 0.725 | 0.309 | 0.433\n",
      "salary                         | 0.786 | 0.220 | 0.344\n",
      "associate-needed               | 0.000 | 0.000 | nan\n",
      "bs-degree-needed               | 0.714 | 0.724 | 0.719\n",
      "ms-or-phd-needed               | 1.000 | 0.143 | 0.250\n",
      "licence-needed                 | 0.531 | 0.354 | 0.425\n",
      "1-year-experience-needed       | 0.500 | 0.081 | 0.139\n",
      "2-4-years-experience-needed    | 0.546 | 0.567 | 0.556\n",
      "5-plus-years-experience-needed | 0.643 | 0.429 | 0.514\n",
      "supervising-job                | 0.726 | 0.455 | 0.560\n",
      "\n",
      "Worst precision: associate-needed\n",
      "Worst recall: associate-needed\n",
      "Worst F1 score: associate-needed\n",
      "\n",
      "General:\n",
      "Precision: 0.661\n",
      "Recall: 0.401\n",
      "F1 score: 0.499\n",
      "#4 F1 score: 0.499\n",
      "\n",
      "Total F1 score: 0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores = []\n",
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "for i, (train, validation) in enumerate(k_fold.split(X)):\n",
    "    X_train, X_validation, y_train, y_validation = X[train], X[validation], y[train], y[validation]\n",
    "\n",
    "    fit_models(models, X_preprocessor, y_preprocessors, X_train, y_train)\n",
    "    y_output = predict_models(models, X_preprocessor, y_preprocessors, X_validation)\n",
    "    \n",
    "    score = calculate_f1_score(y_validation, y_output)\n",
    "    scores.append(score)\n",
    "    print '#{0} F1 score: {1:.3f}'.format(i, score)\n",
    "    print\n",
    "    \n",
    "f1_score = np.mean(scores)\n",
    "    \n",
    "print 'Total F1 score: {0:.3f}'.format(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_test_data(filename):\n",
    "    with open(filename) as fd:\n",
    "        reader = csv.reader(fd, delimiter='\\t')\n",
    "        next(reader, None) # ignore header row\n",
    "        X = [row[0] for row in reader]\n",
    "\n",
    "    return np.array(X)\n",
    "\n",
    "X_train, y_train = load_train_data('data/train.tsv')\n",
    "X_test = load_test_data('data/test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with all training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models\n"
     ]
    }
   ],
   "source": [
    "fit_models(models, X_preprocessor, y_preprocessors, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict output from test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with models\n"
     ]
    }
   ],
   "source": [
    "y_output = predict_models(models, X_preprocessor, y_preprocessors, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['licence-needed'], ['hourly-wage', '2-4-years-experience-needed'], ['2-4-years-experience-needed'], ['2-4-years-experience-needed'], ['2-4-years-experience-needed'], [], [], ['2-4-years-experience-needed', 'bs-degree-needed'], ['2-4-years-experience-needed', 'bs-degree-needed'], []]\n"
     ]
    }
   ],
   "source": [
    "print y_output[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_output(filename, output):\n",
    "    with open(filename, 'w') as fd:\n",
    "        fd.write('tags\\n')\n",
    "        \n",
    "        for i, tags in enumerate(output):\n",
    "            fd.write(' '.join(tags))\n",
    "            fd.write('\\n')\n",
    "            \n",
    "save_output('data/tags.tsv', y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save preprocessors and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(filename, obj):\n",
    "    pickle.dump(obj, open(filename, 'w'))\n",
    "\n",
    "save('models/X_preprocessor.pickle', X_preprocessor)\n",
    "save('models/y_preprocessor.pickle', y_preprocessors)\n",
    "save('models/clf_{0:.3f}_f1_score.pickle'.format(f1_score), models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    return pickle.load(open(filename))\n",
    "\n",
    "models = load('models/clf_0.461_f1_score.pickle')\n",
    "X_preprocessors = load('models/X_preprocessor.pickle')\n",
    "y_preprocessors = load('models/y_preprocessor.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
